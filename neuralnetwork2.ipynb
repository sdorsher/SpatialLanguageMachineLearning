{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import os, sys\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from bokeh.plotting import figure, output_notebook, show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def powerlaw(x,a,b,c):\n",
    "    return a*x**b+c\n",
    "\n",
    "def f5(x,a,b,c,d,g,h):\n",
    "    return a*x**5+b*x**4+c*x**3+d*x**2+g*x+h\n",
    "\n",
    "def f3(x,a,b,c,d):\n",
    "    return a*x**3+b*x**2+c*x+d\n",
    "\n",
    "\n",
    "def VowelToConsRatio(name):\n",
    "    \n",
    "    words = sum(c.isalpha() for c in name)\n",
    "    spaces = sum(c.isspace() for c in name)\n",
    "    others = len(name) - words - spaces\n",
    "    vowels = sum(map(name.lower().count, \"aeiou\"))\n",
    "    consonents = words - vowels\n",
    "\n",
    "\n",
    "    return float(vowels)/float(consonents), float(spaces)/float(consonents), float(others)/float(consonents)\n",
    "\n",
    "def CharCount(name):\n",
    "    \n",
    "    words = sum(c.isalpha() for c in name)\n",
    "    spaces = sum(c.isspace() for c in name)\n",
    "    others = len(name) - words - spaces\n",
    "    vowels = sum(map(name.lower().count, \"aeiou\"))\n",
    "    consonents = words - vowels\n",
    "\n",
    "\n",
    "    return int(consonents), int(vowels), int(spaces), int(others)\n",
    "\n",
    "def MergeCount(totalCount, thisCount):\n",
    "    totalCount2=totalCount+thisCount\n",
    "    return totalCount2\n",
    "\n",
    "\n",
    "\n",
    "def LatLongClassMaker(coor):\n",
    "    lat,long=coor\n",
    "    if lat<30:\n",
    "        if long>-90:\n",
    "            return 1 #florida\n",
    "        elif long < -120:\n",
    "            return 2 #hawaii\n",
    "        else:\n",
    "            return 3 #texas\n",
    "    elif lat >50:\n",
    "        return 4 #alaska\n",
    "    elif long> -80 and lat < 40:\n",
    "        return 5 #south east\n",
    "    elif long> -80 and lat >40:\n",
    "        return 6 #new england\n",
    "    elif long< -80:\n",
    "        return int((50-lat)/20.*5)*int((125+long)/45.*9)+7\n",
    "    else:\n",
    "        return 0\n",
    "    #worst mapping ever-- ignores new england and city diversity\n",
    "    return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=[]\n",
    "coords=[]\n",
    "charcountlist=[]\n",
    "file = open(\"airports-extended.dat.txt\",\"r\")\n",
    "for line in file:\n",
    "    line=re.split(',',line);\n",
    "\n",
    "    if line[3] == \"\\\"United States\\\"\":\n",
    "        #thisratioV, thisratioS, thisratioO=VowelToConsRatio(line[1]);\n",
    "        #ratio.append([thisratioV,thisratioS,thisratioO])\n",
    "        charcountlist.append(np.array([CharCount(line[1])]))\n",
    "        coords.append(np.array([float(line[6]),float(line[7])]))\n",
    "\n",
    "\n",
    "#ratioarray=np.empty([len(ratio),3])\n",
    "coordsarray=np.empty([len(coords),2])\n",
    "regionarray=np.empty([len(coords)])\n",
    "charcountarray=np.empty([len(coords),4])\n",
    "\n",
    "#for i, rat in enumerate(ratio):\n",
    "#    ratioarray[i,:]=rat\n",
    "for i, charct in enumerate(charcountlist):\n",
    "    charcountarray[i,:]=charct\n",
    "for i,coor in enumerate(coords):\n",
    "    coordsarray[i,:]=coor\n",
    "#    outputcoor=LatLongClassMaker(coor)\n",
    "#    regionarray[i]=outputcoor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2294, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(charcountarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testphrases=[\"Ufda!\", \"I just dont know about that\", \"Howdy, pardner\", \"Where are we?\", \"I thank whatever gods may be for my unconquerable soul.\", \"I welcome our new robot overlords\", \"l33t h4k3rs\", \"I know you I walked with you once upon a dream\", \"These stories dont mean anything if you have no one to tell them to\", \"Baby you have the sort of hands that rip me apart\",\"Multi-messenger astronomy\", \"Rainbow flag\", \"I prefer They or He?\", \"numerical relativity\", \"LIGO\", \"scalar field\", \"Osculating Orbits\", \"Monte-Carlo Simulation\", \"Data Analysis\", \"Data Science\", \"Parallelization\", \"Paralyzation\", \"Partial disability\", \"Non-epileptic seizures\", \"Wednesday Lunch\", \"Tuesday Lunch\", \"Thursday Lunch\", \"Guild Wars\", \"Elvenar\", \"Good Apple\"]\n",
    "\n",
    "\n",
    "colleaguephrases=[\"general relativity\", \"black hole\", \"loop quantum gravity\",  \"quantization\", \"space-time\", \"Hamiltonian constraint\", \"Ashtekar\", \"LiSA\", \"LIGO\", \"group\", \"white hole\", \"scalar field\", \"numerical relativity\", \"cosmology\", \"diffeomorphism\", \"continuum limit\", \"David Berger\", \"Reisner-Nordstrom\", \"black hole spacetime\", \"initial data\", \"interpretation of quantum mechanics\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ufda!\n",
      "I just dont know about that\n",
      "Howdy, pardner\n",
      "Where are we?\n",
      "I thank whatever gods may be for my unconquerable soul.\n",
      "I welcome our new robot overlords\n",
      "l33t h4k3rs\n",
      "I know you I walked with you once upon a dream\n",
      "These stories dont mean anything if you have no one to tell them to\n",
      "Baby you have the sort of hands that rip me apart\n",
      "Multi-messenger astronomy\n",
      "Rainbow flag\n",
      "I prefer They or He?\n",
      "numerical relativity\n",
      "LIGO\n",
      "scalar field\n",
      "Osculating Orbits\n",
      "Monte-Carlo Simulation\n",
      "Data Analysis\n",
      "Data Science\n",
      "Parallelization\n",
      "Paralyzation\n",
      "Partial disability\n",
      "Non-epileptic seizures\n",
      "Wednesday Lunch\n",
      "Tuesday Lunch\n",
      "Thursday Lunch\n",
      "Guild Wars\n",
      "Elvenar\n",
      "Good Apple\n",
      "general relativity\n",
      "black hole\n",
      "loop quantum gravity\n",
      "quantization\n",
      "space-time\n",
      "Hamiltonian constraint\n",
      "Ashtekar\n",
      "LiSA\n",
      "LIGO\n",
      "group\n",
      "white hole\n",
      "scalar field\n",
      "numerical relativity\n",
      "cosmology\n",
      "diffeomorphism\n",
      "continuum limit\n",
      "David Berger\n",
      "Reisner-Nordstrom\n",
      "black hole spacetime\n",
      "initial data\n",
      "interpretation of quantum mechanics\n",
      "[[1.0, 0.0, 0.5], [0.5714285714285714, 0.35714285714285715, 0.0], [0.3333333333333333, 0.1111111111111111, 0.1111111111111111], [1.0, 0.4, 0.2], [0.6071428571428571, 0.32142857142857145, 0.03571428571428571], [0.75, 0.3125, 0.0], [0.0, 0.16666666666666666, 0.6666666666666666], [0.8947368421052632, 0.5263157894736842, 0.0], [0.6875, 0.40625, 0.0], [0.56, 0.4, 0.0], [0.5333333333333333, 0.06666666666666667, 0.06666666666666667], [0.5714285714285714, 0.14285714285714285, 0.0], [0.6666666666666666, 0.4444444444444444, 0.1111111111111111], [0.7272727272727273, 0.09090909090909091, 0.0], [1.0, 0.0, 0.0], [0.5714285714285714, 0.14285714285714285, 0.0], [0.6, 0.1, 0.0], [0.8181818181818182, 0.09090909090909091, 0.09090909090909091], [0.7142857142857143, 0.14285714285714285, 0.0], [0.8333333333333334, 0.16666666666666666, 0.0], [0.875, 0.0, 0.0], [0.7142857142857143, 0.0, 0.0], [0.7, 0.1, 0.0], [0.8181818181818182, 0.09090909090909091, 0.09090909090909091], [0.4, 0.1, 0.0], [0.5, 0.125, 0.0], [0.3, 0.1, 0.0], [0.5, 0.16666666666666666, 0.0], [0.75, 0.0, 0.0], [0.8, 0.2, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "xphrases=[]\n",
    "for phrase in testphrases:\n",
    "    print(phrase)\n",
    "    vtc, stc, otc = VowelToConsRatio(phrase)\n",
    "    xphrases.append([vtc,stc,otc])\n",
    "xcolleague=[]\n",
    "for phrase in colleaguephrases:\n",
    "    print(phrase)\n",
    "    vtc, stc, otc = VowelToConsRatio(phrase)\n",
    "    xcolleague.append([vtc,stc,otc])\n",
    "\n",
    "print(xphrases)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(charcountarray,regionarray,test_size=0.5,shuffle=True, random_state=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1147"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainshp=np.shape(ytrain)\n",
    "testshp=np.shape(ytest)\n",
    "trainshp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain_flat = ytrain.flatten()\n",
    "ytest_flat=ytest.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layers=20 #20 lines of division is my biased theory\n",
    "hidden_size=3 #enough to draw a line with an offset I think, plus an little variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = None\n",
    "\n",
    "def reset_vars():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def reset_tf():\n",
    "    global sess\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1147"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 1e95b68] second attempt at neural network, needlessly complicated, going back to first attempt\n",
      " 1 file changed, 491 insertions(+)\n",
      " create mode 100644 neuralnetwork2.ipynb\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git add neuralnetwork2.ipynb\n",
    "git commit neuralnetwork2.ipynb -m \"second attempt at neural network, needlessly complicated, going back to first attempt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lstm(x, lstm_init_value, n_chars, lstm_size, n_layers):\n",
    "    # LSTM\n",
    "    lstm = tf.contrib.rnn.MultiRNNCell(\n",
    "        [tf.contrib.rnn.BasicLSTMCell(lstm_size, forget_bias=1.0, state_is_tuple=False)\n",
    "         for _ in np.xrange(n_layers)],\n",
    "        state_is_tuple=False)\n",
    "\n",
    "    # Iteratively compute output of recurrent network\n",
    "    out, lstm_new_state = tf.nn.dynamic_rnn(lstm, x, initial_state=lstm_init_value, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation (FC layer on top of the LSTM net)\n",
    "    out_reshaped = tf.reshape(out, [-1, lstm_size])\n",
    "    y = tf.layers.dense(out_reshaped, n_chars, activation=None)\n",
    "    \n",
    "    return y, tf.shape(out), lstm_new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_layers = 4\n",
    "n_labels = max(max(ytrain),max(ytest))\n",
    "lstm_size = 16\n",
    "n_chars=n_labels #borrowing someone else's code\n",
    "time_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_tf()\n",
    "\n",
    "x = tf.placeholder(tf.int32, shape=(None, None), name=\"x\")\n",
    "y_true = tf.placeholder(tf.int32, (None, None))\n",
    "lstm_init_value = tf.placeholder(tf.float32, shape=(None, n_layers*2*lstm_size),\n",
    "                                 name=\"lstm_init_value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_enc = tf.one_hot(xtrain.flatten(), depth=n_labels)\n",
    "y_true_enc = tf.one_hot(ytrain.flatten(), depth=n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'xrange'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9fc268906bee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_new_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_init_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-3fb53dca2677>\u001b[0m in \u001b[0;36mmake_lstm\u001b[0;34m(x, lstm_init_value, n_chars, lstm_size, n_layers)\u001b[0m\n\u001b[1;32m      3\u001b[0m     lstm = tf.contrib.rnn.MultiRNNCell(\n\u001b[1;32m      4\u001b[0m         [tf.contrib.rnn.BasicLSTMCell(lstm_size, forget_bias=1.0, state_is_tuple=False)\n\u001b[0;32m----> 5\u001b[0;31m          for _ in np.xrange(n_layers)],\n\u001b[0m\u001b[1;32m      6\u001b[0m         state_is_tuple=False)\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'xrange'"
     ]
    }
   ],
   "source": [
    "y_pred, out_shape, lstm_new_state = make_lstm(x_enc, lstm_init_value, n_labels, lstm_size, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_out = tf.reshape(tf.nn.softmax(y_pred), \n",
    "                       (out_shape[0], out_shape[1], n_chars))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
