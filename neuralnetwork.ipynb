{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import os, sys\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "file = open(\"airports-extended.dat.txt\",\"r\")\n",
    "import tensorflow as tf\n",
    "from bokeh.plotting import figure, output_notebook, show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def powerlaw(x,a,b,c):\n",
    "    return a*x**b+c\n",
    "\n",
    "def f5(x,a,b,c,d,g,h):\n",
    "    return a*x**5+b*x**4+c*x**3+d*x**2+g*x+h\n",
    "\n",
    "def f3(x,a,b,c,d):\n",
    "    return a*x**3+b*x**2+c*x+d\n",
    "\n",
    "\n",
    "def VowelToConsRatio(name):\n",
    "    \n",
    "    words = sum(c.isalpha() for c in name)\n",
    "    spaces = sum(c.isspace() for c in name)\n",
    "    others = len(name) - words - spaces\n",
    "    vowels = sum(map(name.lower().count, \"aeiou\"))\n",
    "    consonents = words - vowels\n",
    "\n",
    "\n",
    "    return float(vowels)/float(consonents), float(spaces)/float(consonents), float(others)/float(consonents)\n",
    "\n",
    "def CharCount(name):\n",
    "    \n",
    "    words = sum(c.isalpha() for c in name)\n",
    "    spaces = sum(c.isspace() for c in name)\n",
    "    others = len(name) - words - spaces\n",
    "    vowels = sum(map(name.lower().count, \"aeiou\"))\n",
    "    consonents = words - vowels\n",
    "\n",
    "\n",
    "    return int(consonents), int(vowels), int(spaces), int(others)\n",
    "\n",
    "\n",
    "\n",
    "def MergeCount(totalCount, thisCount):\n",
    "    totalCount2=totalCount+thisCount\n",
    "    return totalCount2\n",
    "\n",
    "\n",
    "\n",
    "def LatLongClassMaker(coor):\n",
    "    lat,long=coor\n",
    "    if lat<30:\n",
    "        if long>-90:\n",
    "            return 1 #florida\n",
    "        elif long < -120:\n",
    "            return 2 #hawaii\n",
    "        else:\n",
    "            return 3 #texas\n",
    "    elif lat >50:\n",
    "        return 4 #alaska\n",
    "    elif long> -80 and lat < 40:\n",
    "        return 5 #south east\n",
    "    elif long> -80 and lat >40:\n",
    "        return 6 #new england\n",
    "    elif long< -80:\n",
    "        return int((50-lat)/20.*5)*int((125+long)/45.*9)+7\n",
    "    else:\n",
    "        return 0\n",
    "    #worst mapping ever-- ignores new england and city diversity\n",
    "    return 0\n",
    "ratio=[]\n",
    "coords=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio=[]\n",
    "coords=[]\n",
    "charcountlist=[]\n",
    "file = open(\"airports-extended.dat.txt\",\"r\")\n",
    "for line in file:\n",
    "    line=re.split(',',line);\n",
    "\n",
    "    if line[3] == \"\\\"United States\\\"\":\n",
    "        thisratioV, thisratioS, thisratioO=VowelToConsRatio(line[1]);\n",
    "        ratio.append([thisratioV,thisratioS,thisratioO])\n",
    "        charcountlist.append(np.array([CharCount(line[1])]))\n",
    "        coords.append([float(line[6]),float(line[7])])\n",
    "\n",
    "\n",
    "ratioarray=np.empty([len(ratio),3])\n",
    "coordsarray=np.empty([len(coords),2])\n",
    "regionarray=np.empty([len(coords)])\n",
    "charcountarray=np.empty([len(coords),4])\n",
    "\n",
    "for i, rat in enumerate(ratio):\n",
    "    ratioarray[i,:]=rat\n",
    "for i, charct in enumerate(charcountlist):\n",
    "    charcountarray[i,:]=charct\n",
    "for i,coor in enumerate(coords):\n",
    "    coordsarray[i,:]=coor\n",
    "#    outputcoor=LatLongClassMaker(coor)\n",
    "#    regionarray[i]=outputcoor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testphrases=[\"Ufda!\", \"I just dont know about that\", \"Howdy, pardner\", \"Where are we?\", \"I thank whatever gods may be for my unconquerable soul.\", \"I welcome our new robot overlords\", \"l33t h4k3rs\", \"I know you I walked with you once upon a dream\", \"These stories dont mean anything if you have no one to tell them to\", \"Baby you have the sort of hands that rip me apart\",\"Multi-messenger astronomy\", \"Rainbow flag\", \"I prefer They or He?\", \"numerical relativity\", \"LIGO\", \"scalar field\", \"Osculating Orbits\", \"Monte-Carlo Simulation\", \"Data Analysis\", \"Data Science\", \"Parallelization\", \"Paralyzation\", \"Partial disability\", \"Non-epileptic seizures\", \"Wednesday Lunch\", \"Tuesday Lunch\", \"Thursday Lunch\", \"Guild Wars\", \"Elvenar\", \"Good Apple\"]\n",
    "\n",
    "\n",
    "colleaguephrases=[\"general relativity\", \"black hole\", \"loop quantum gravity\",  \"quantization\", \"space-time\", \"Hamiltonian constraint\", \"Ashtekar\", \"LiSA\", \"LIGO\", \"group\", \"white hole\", \"scalar field\", \"numerical relativity\", \"cosmology\", \"diffeomorphism\", \"continuum limit\", \"David Berger\", \"Reisner-Nordstrom\", \"black hole spacetime\", \"initial data\", \"interpretation of quantum mechanics\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ufda!\n",
      "I just dont know about that\n",
      "Howdy, pardner\n",
      "Where are we?\n",
      "I thank whatever gods may be for my unconquerable soul.\n",
      "I welcome our new robot overlords\n",
      "l33t h4k3rs\n",
      "I know you I walked with you once upon a dream\n",
      "These stories dont mean anything if you have no one to tell them to\n",
      "Baby you have the sort of hands that rip me apart\n",
      "Multi-messenger astronomy\n",
      "Rainbow flag\n",
      "I prefer They or He?\n",
      "numerical relativity\n",
      "LIGO\n",
      "scalar field\n",
      "Osculating Orbits\n",
      "Monte-Carlo Simulation\n",
      "Data Analysis\n",
      "Data Science\n",
      "Parallelization\n",
      "Paralyzation\n",
      "Partial disability\n",
      "Non-epileptic seizures\n",
      "Wednesday Lunch\n",
      "Tuesday Lunch\n",
      "Thursday Lunch\n",
      "Guild Wars\n",
      "Elvenar\n",
      "Good Apple\n",
      "general relativity\n",
      "black hole\n",
      "loop quantum gravity\n",
      "quantization\n",
      "space-time\n",
      "Hamiltonian constraint\n",
      "Ashtekar\n",
      "LiSA\n",
      "LIGO\n",
      "group\n",
      "white hole\n",
      "scalar field\n",
      "numerical relativity\n",
      "cosmology\n",
      "diffeomorphism\n",
      "continuum limit\n",
      "David Berger\n",
      "Reisner-Nordstrom\n",
      "black hole spacetime\n",
      "initial data\n",
      "interpretation of quantum mechanics\n",
      "[[1.0, 0.0, 0.5], [0.5714285714285714, 0.35714285714285715, 0.0], [0.3333333333333333, 0.1111111111111111, 0.1111111111111111], [1.0, 0.4, 0.2], [0.6071428571428571, 0.32142857142857145, 0.03571428571428571], [0.75, 0.3125, 0.0], [0.0, 0.16666666666666666, 0.6666666666666666], [0.8947368421052632, 0.5263157894736842, 0.0], [0.6875, 0.40625, 0.0], [0.56, 0.4, 0.0], [0.5333333333333333, 0.06666666666666667, 0.06666666666666667], [0.5714285714285714, 0.14285714285714285, 0.0], [0.6666666666666666, 0.4444444444444444, 0.1111111111111111], [0.7272727272727273, 0.09090909090909091, 0.0], [1.0, 0.0, 0.0], [0.5714285714285714, 0.14285714285714285, 0.0], [0.6, 0.1, 0.0], [0.8181818181818182, 0.09090909090909091, 0.09090909090909091], [0.7142857142857143, 0.14285714285714285, 0.0], [0.8333333333333334, 0.16666666666666666, 0.0], [0.875, 0.0, 0.0], [0.7142857142857143, 0.0, 0.0], [0.7, 0.1, 0.0], [0.8181818181818182, 0.09090909090909091, 0.09090909090909091], [0.4, 0.1, 0.0], [0.5, 0.125, 0.0], [0.3, 0.1, 0.0], [0.5, 0.16666666666666666, 0.0], [0.75, 0.0, 0.0], [0.8, 0.2, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "xphrases=[]\n",
    "for phrase in testphrases:\n",
    "    print(phrase)\n",
    "    vtc, stc, otc = VowelToConsRatio(phrase)\n",
    "    xphrases.append([vtc,stc,otc])\n",
    "xcolleague=[]\n",
    "for phrase in colleaguephrases:\n",
    "    print(phrase)\n",
    "    vtc, stc, otc = VowelToConsRatio(phrase)\n",
    "    xcolleague.append([vtc,stc,otc])\n",
    "\n",
    "print(xphrases)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(charcountarray,regionarray,test_size=0.33,shuffle=False, random_state=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainshp=np.shape(ytrain)\n",
    "testshp=np.shape(ytest)\n",
    "trainshp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain_flat = ytrain.flatten()\n",
    "ytest_flat=ytest.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_layers=20 #20 lines of division is my biased theory\n",
    "hidden_size=3 #enough to draw a line with an offset I think, plus an little variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = None\n",
    "\n",
    "def reset_vars():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def reset_tf():\n",
    "    global sess\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master f9441db] first attempt at neural network\n",
      " 1 file changed, 443 insertions(+)\n",
      " create mode 100644 neuralnetwork.ipynb\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "git add neuralnetwork.ipynb\n",
    "git commit neuralnetwork.ipynb -m \"first attempt at neural network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'b' of 'MatMul' Op has type float32 that does not match type float64 of argument 'a'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    511\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    946\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    948\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype float64 for Tensor with dtype float32: 'Tensor(\"weight1/read:0\", shape=(1536, 3), dtype=float32)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-25a1b117e50b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weight1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bias1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2122\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   4277\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4278\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4279\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   4280\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4281\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/data3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    544\u001b[0m                   \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[0;32m--> 546\u001b[0;31m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'b' of 'MatMul' Op has type float32 that does not match type float64 of argument 'a'."
     ]
    }
   ],
   "source": [
    "\n",
    "W1 = tf.Variable(tf.random_normal([len(x), hidden_size], seed=42), name=\"weight1\")\n",
    "b1 = tf.Variable(tf.zeros([hidden_size]), name=\"bias1\")\n",
    "hidden = tf.matmul(x, W1) + b1\n",
    "for i in np.arange(hidden_layers):\n",
    "\n",
    "    W = tf.Variable(tf.random_normal([hidden_size, hidden_size]), name=\"weight\"+str(i+2))\n",
    "    b = tf.Variable(tf.random_normal([hidden_size]), name=\"bias\"+str(i+2))\n",
    "    hidden = tf.matmul(hidden, W) + b\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([hidden_size, 1]), name=\"finalweight\")\n",
    "b2 = tf.Variable(tf.random_normal([1]), name=\"finalbias\")\n",
    "y = tf.matmul(hidden, W2) + b2\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=ytrain, \n",
    "                                                              labels=y_label))\n",
    "train = tf.train.GradientDescentOptimizer(1e-1).minimize(loss)\n",
    "\n",
    "predicted = tf.cast(tf.nn.sigmoid(ytrain) > 0.5, np.float32)\n",
    "#accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,y_label),np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_vars()\n",
    "\n",
    "for i in range(3000):\n",
    "    sess.run(train,\n",
    "             feed_dict={x: xtrain, y_label: ytrain})\n",
    "    if i % 300 == 0:\n",
    "        print sess.run([loss, accuracy], \n",
    "                       feed_dict={x: xtrain, y_label: ytrain}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
